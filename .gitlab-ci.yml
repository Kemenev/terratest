stages:
  - validate
  - plan
  - repair
  - apply

variables:
  TF_BACKEND_ADDRESS: "$CI_API_V4_URL/projects/$CI_PROJECT_ID/terraform/state/$CI_COMMIT_REF_NAME"
  TF_BACKEND_LOCK: "$CI_API_V4_URL/projects/$CI_PROJECT_ID/terraform/state/$CI_COMMIT_REF_NAME/lock"
  TF_VAR_tf_env: $CI_COMMIT_REF_NAME

.tf_job: &tf_job
  image: alpine/terragrunt:1.12.2
  tags:
    - docker
  before_script:
    - unzip -o terraform-plugins.zip
    - export TF_VAR_vsphere_password=$(echo "$TF_VAR_vsphere_password" | base64 -d)
    - mkdir -p ~/.terraform.d/plugins/registry.terraform.io/hashicorp/vsphere/2.15.0/linux_amd64
    - mkdir -p ~/.terraform.d/plugins/registry.terraform.io/e-breuninger/netbox/5.0.0/linux_amd64
    - cp terraform-plugins/registry.terraform.io/hashicorp/vsphere/2.15.0/terraform-provider-vsphere_v2.15.0 ~/.terraform.d/plugins/registry.terraform.io/hashicorp/vsphere/2.15.0/linux_amd64
    - cp terraform-plugins/registry.terraform.io/e-breuninger/netbox/5.0.0/linux_amd64/terraform-provider-netbox_v5.0.0 ~/.terraform.d/plugins/registry.terraform.io/e-breuninger/netbox/5.0.0/linux_amd64
    - chmod +x ~/.terraform.d/plugins/registry.terraform.io/hashicorp/vsphere/2.15.0/linux_amd64/terraform-provider-vsphere_v2.15.0
    - chmod +x ~/.terraform.d/plugins/registry.terraform.io/e-breuninger/netbox/5.0.0/linux_amd64/terraform-provider-netbox_v5.0.0
    - echo "$NETBOX_CERT" > /usr/local/share/ca-certificates/netbox.crt
    - update-ca-certificates
    - terraform init
      -backend-config="address=$TF_BACKEND_ADDRESS"
      -backend-config="username=gitlab-ci-token"
      -backend-config="password=$CI_JOB_TOKEN"

validate:
  <<: *tf_job
  stage: validate
  script:
    - terraform validate

plan:
  <<: *tf_job
  stage: plan
  # plan может упасть (guard / prevent_destroy), но pipeline должен продолжиться,
  # чтобы можно было нажать manual jobs (retire/recreate).
  allow_failure: true
  script:
    # Гарантируем существование файлов для artifacts (чтобы GitLab не ругался)
    - touch tfplan.txt state_before.txt vm_creates_or_replaces.txt missing_vm_addresses.txt missing_vm_names.txt netbox_plan_remove.txt plan.log

    # Снимок state ДО plan (нужно, чтобы отличать "новые" VM от пересоздания)
    - terraform state list > state_before.txt || true

    # Запускаем plan так, чтобы даже при ошибке у нас остался лог (plan.log)
    - |
      set +e
      terraform plan -out=tfplan 2>&1 | tee plan.log
      PLAN_RC=${PIPESTATUS[0]}
      set -e

      # Если tfplan создан — делаем tfplan.txt
      if [ -f tfplan ]; then
        terraform show -no-color tfplan > tfplan.txt || true
      else
        : > tfplan.txt
      fi

      # Извлекаем адреса ресурсов, на которых сработал prevent_destroy (в первую очередь NetBox)
      # Нам нужен именно адрес: netbox_ip_address.ip["..."]
      sed -n 's/^.*Resource \([^ ]\+\) has lifecycle\.prevent_destroy set.*$/\1/p' plan.log \
        | grep '^netbox_' \
        | sort -u > netbox_plan_remove.txt || true

      echo "=== PLAN_RC=$PLAN_RC ==="
      echo "=== netbox_plan_remove.txt ==="
      cat netbox_plan_remove.txt || true

    # Guard по vSphere: если Terraform хочет создать/заменить VM, которая уже была в state — сигнализируем.
    - |
      grep 'vsphere_virtual_machine' tfplan.txt | grep -E 'will be created|will be replaced|must be replaced|destroyed and then created' \
        | sed -E 's/^.*# *//; s/ will be created$//; s/ will be replaced$//; s/ must be replaced$//; s/ destroyed and then created$//' \
        | sort -u > vm_creates_or_replaces.txt || true

      grep -Fx -f state_before.txt vm_creates_or_replaces.txt > missing_vm_addresses.txt || true
      sed -n 's/.*\["\([^"]\+\)"\].*/\1/p' missing_vm_addresses.txt | sort -u > missing_vm_names.txt || true

      if [ -s missing_vm_addresses.txt ]; then
        echo "ERROR: Обнаружены VM, которые Terraform пытается пересоздать (скорее всего удалены вручную):"
        cat missing_vm_names.txt
        echo ""
        echo "Дальше:"
        echo " - если VM НЕ нужна -> убери ее из YAML/конфига и запусти manual job: retire_missing"
        echo " - если VM нужна -> запусти manual job: recreate_missing"
        exit 1
      fi
  artifacts:
    when: always
    paths:
      - tfplan
      - tfplan.txt
      - plan.log
      - state_before.txt
      - vm_creates_or_replaces.txt
      - missing_vm_addresses.txt
      - missing_vm_names.txt
      - netbox_plan_remove.txt
      - .terraform.lock.hcl
      - .terraform
      - tf-debug.log
    expire_in: 1 day

# Retire: NetBox НЕ удаляем. Просто "отвязываем" из Terraform state netbox_* ресурсы,
# которые Terraform хотел удалить (они попали в netbox_plan_remove.txt из plan.log).
retire_missing:
  <<: *tf_job
  stage: repair
  when: manual
  allow_failure: false
  needs:
    - job: plan
      artifacts: true
  script:
    - touch retire_netbox_state_rm.txt
    - |
      if [ ! -s netbox_plan_remove.txt ]; then
        echo "netbox_plan_remove.txt отсутствует или пуст — нечего отвязывать."
        echo "Если в plan была ошибка prevent_destroy, проверь plan.log в artifacts."
        exit 0
      fi

      echo "Retire: отвязываем из state netbox_* ресурсы (в NetBox ничего не удаляется):"
      cat netbox_plan_remove.txt

      cp netbox_plan_remove.txt retire_netbox_state_rm.txt

      while read -r addr; do
        [ -z "$addr" ] && continue
        terraform state rm "$addr" || true
      done < netbox_plan_remove.txt

      echo "Готово. NetBox записи сохранены, Terraform больше не пытается их удалять."
  artifacts:
    when: always
    paths:
      - retire_netbox_state_rm.txt
    expire_in: 1 day

# Recreate: НЕ применяем tfplan (он может отсутствовать/быть битым, если plan падал).
# Делаем новый apply по текущей конфигурации.
recreate_missing:
  <<: *tf_job
  stage: apply
  when: manual
  allow_failure: false
  needs:
    - job: plan
      artifacts: true
  script:
    - |
      if [ ! -s missing_vm_names.txt ]; then
        echo "missing_vm_names.txt пуст — нечего пересоздавать."
        exit 0
      fi

      echo "Recreate missing VM (новый apply, без tfplan):"
      cat missing_vm_names.txt

      terraform apply -auto-approve

apply:
  <<: *tf_job
  stage: apply
  when: manual
  allow_failure: false
  needs:
    - job: plan
      artifacts: true
  script:
    - |
      # Защита от случайного пересоздания: если Guard нашел missing VM,
      # используй manual job recreate_missing (восстановить) или retire_missing (удалить навсегда: сначала YAML, потом отвязка NetBox state).
      if [ -s missing_vm_addresses.txt ]; then
        echo "ERROR: Обнаружены missing VM."
        echo "Используй manual job recreate_missing (восстановить) или retire_missing (удалить навсегда)."
        cat missing_vm_names.txt || true
        exit 1
      fi

      # Если tfplan не создан (plan падал) — apply тоже не должен запускаться
      if [ ! -f tfplan ]; then
        echo "ERROR: tfplan отсутствует (plan упал)."
        echo "Apply невозможен. Используй recreate_missing или retire_missing, либо исправь plan."
        exit 1
      fi

      terraform apply -auto-approve tfplan
